{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b50f9f5-904c-47f5-bd50-e5dcd03b6e78",
   "metadata": {},
   "source": [
    "# Introduction to Ollama and LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72fe44e-c3ac-4563-b9e5-29eef2ece587",
   "metadata": {},
   "source": [
    "## Install and Explore Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c718813-371b-4814-a1d6-e3270791f461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to install in Python\n",
    "!pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed0bb4d-fead-4461-ae47-2635518fee8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84bf480-1ca4-400b-b6ea-4fb02e25491f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67b6677-b109-4da1-a5c4-b10210934860",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama pull moondream:v2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd92fed6-6e79-498e-9d6c-88b6d65b9430",
   "metadata": {},
   "source": [
    "## Use Ollama API in Python Program\n",
    "https://github.com/ollama/ollama-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96fd3d03-b758-489c-a227-6ac0121656ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "from ollama import chat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d485d9e-2f04-4b48-b2eb-fb3f32eccd71",
   "metadata": {},
   "source": [
    "## Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f06d2803-2911-41f0-9e37-afc2b2b686ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ai(llm, mymessage):\n",
    "    response = chat(model=llm, \n",
    "                    messages=[{'role': 'user','content': mymessage}],\n",
    "                    # stream=True, # optional, enables formatted output\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea57bdbc-4103-475b-b30b-fed44fa179da",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = \"gemma3:12b\"\n",
    "# llm = \"gpt-oss:20b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999d31ca-378f-433a-9c30-6a0c68c40200",
   "metadata": {},
   "outputs": [],
   "source": [
    "mymessage = \"What is Ollama?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a34268-2496-47a4-919d-965a815c49dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no stream\n",
    "result = ai(llm, mymessage)\n",
    "result.message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c28a1d-4ea5-40c8-add4-f146b9dcb8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stream\n",
    "stream = ai(llm, mymessage)\n",
    "for chunk in stream:\n",
    "    print(chunk['message']['content'], end='', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f992f37-3455-4e0a-8191-8573473f14de",
   "metadata": {},
   "source": [
    "## Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d012817-e0b7-4fb2-be44-01b5eff6bb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#llm = \"llama3.2-vision:latest\"\n",
    "llm = \"gemma3:12b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a976a9c-562c-4e74-955b-f6c25bbc6a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mymessage = \"Explain this image: /Users/tdi/Documents/GitHub/foxdocs/dat-bi/Media/confusion.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04d544ee-0553-47d4-8d45-60295c7ce0a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "tuple indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m stream \u001b[38;5;241m=\u001b[39m ai(llm, mymessage)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m stream:\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(chunk[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m], end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: tuple indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "stream = ai(llm, mymessage)\n",
    "for chunk in stream:\n",
    "    print(chunk['message']['content'], end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac92818-b07e-4153-a56c-08ac160a47f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3976ba30-74b0-4bad-9768-e02b455480eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
